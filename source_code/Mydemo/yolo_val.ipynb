{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-10/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:01<00:47,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:26<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.625      0.582      0.601      0.294\n",
      "Speed: 0.9ms preprocess, 4.5ms inference, 0.0ms loss, 15.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val25\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-15/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:01<00:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:03<00:52,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:28<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.635      0.557      0.579      0.288\n",
      "Speed: 0.9ms preprocess, 4.5ms inference, 0.0ms loss, 14.9ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val26\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-20/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:02<01:08,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:27<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.604      0.548      0.584      0.291\n",
      "Speed: 1.0ms preprocess, 4.6ms inference, 0.0ms loss, 11.9ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val27\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-30/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:02<00:58,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:04<01:07,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  10%|â–ˆ         | 3/29 [00:10<01:46,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:30<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.574      0.593      0.572      0.282\n",
      "Speed: 0.9ms preprocess, 4.2ms inference, 0.0ms loss, 26.5ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val28\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-50/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:24<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.664       0.57      0.604      0.293\n",
      "Speed: 5.4ms preprocess, 4.6ms inference, 0.0ms loss, 8.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val29\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-100/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:33<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.595       0.58        0.6      0.288\n",
      "Speed: 0.9ms preprocess, 11.8ms inference, 0.0ms loss, 7.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val30\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_-150/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:01<00:49,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:07<01:58,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:36<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.487      0.374      0.387      0.164\n",
      "Speed: 0.8ms preprocess, 4.1ms inference, 0.0ms loss, 35.4ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val31\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_10/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:01<00:51,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:30<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.535       0.55      0.555       0.27\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 0.0ms loss, 11.2ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val32\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:01<00:30,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:04<01:10,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  10%|â–ˆ         | 3/29 [00:10<01:41,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:37<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687       0.63      0.601        0.6      0.302\n",
      "Speed: 1.1ms preprocess, 4.8ms inference, 0.0ms loss, 45.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val33\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_20/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:02<01:08,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:08<02:03,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:33<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.568      0.549       0.55      0.265\n",
      "Speed: 0.9ms preprocess, 4.5ms inference, 0.0ms loss, 27.3ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val34\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_30/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:26<06:54, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:53<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.623      0.557      0.584      0.289\n",
      "Speed: 1.1ms preprocess, 4.6ms inference, 0.0ms loss, 21.4ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val35\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_50/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–Ž         | 1/29 [00:02<00:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:40<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.568       0.57      0.559      0.276\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 0.0ms loss, 40.2ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val36\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_60/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   7%|â–‹         | 2/29 [00:03<00:42,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 1.300s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:30<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.578      0.635      0.607      0.304\n",
      "Speed: 1.1ms preprocess, 4.7ms inference, 0.0ms loss, 19.6ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val37\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_70/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:29<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.603      0.496      0.513      0.241\n",
      "Speed: 0.9ms preprocess, 14.2ms inference, 0.0ms loss, 8.6ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val38\u001b[0m\n",
      "Ultralytics YOLOv8.0.234 ðŸš€ Python-3.9.18 torch-2.1.2+cu121 CUDA:0 (NVIDIA TITAN Xp, 12187MiB)\n",
      "                                                            CUDA:1 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:2 (NVIDIA TITAN Xp, 12190MiB)\n",
      "                                                            CUDA:3 (NVIDIA TITAN Xp, 12190MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Data4/student_zhihan_data/data/GC10-DET_brightness_90/valid/labels.cache... 456 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456/456 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:49<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456        687      0.613      0.576      0.591      0.296\n",
      "Speed: 1.2ms preprocess, 4.6ms inference, 0.0ms loss, 9.7ms postprocess per image\n",
      "Results saved to \u001b[1m/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/val39\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "records = {}\n",
    "for i in [-10, -15, -20, -25, -30, -50, -100, -150, 10, 0, 20, 30, 50, 60, 70, 90, 110]:\n",
    "    if i != 0:\n",
    "        model_path = os.path.join('/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/GC10-DET_brightness_%d detect by yolov8n/weights/best.pt' % i)\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        \n",
    "        yaml_path = os.path.join('/Data4/student_zhihan_data/data/GC10-DET_brightness_%d/data.yaml' % i)\n",
    "        if not os.path.exists(yaml_path):\n",
    "            print(yaml_path)\n",
    "        \n",
    "        # Read the YAML file\n",
    "        with open(yaml_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "\n",
    "        # Append the new key-value pair\n",
    "        if 'path' not in data:\n",
    "            data['path'] = '/Data4/student_zhihan_data/data/GC10-DET_brightness_%d' % i\n",
    "        \n",
    "        # Write the modified data structure back to the YAML file\n",
    "        with open(yaml_path, 'w') as file:\n",
    "            yaml.dump(data, file)\n",
    "        \n",
    "        model = YOLO(model_path)  # load a custom model\n",
    "        metrics = model.val(data='/Data4/student_zhihan_data/data/GC10-DET_brightness_%d/data.yaml' % i, device='0,1,2,3', split='val', verbose=False)  # no arguments needed, dataset and settings remembered \n",
    "        records[i] = metrics \n",
    "    else:\n",
    "        model_path = os.path.join('/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/GC10-DET detect by yolov8n5/weights/best.pt')\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        \n",
    "        yaml_path = os.path.join('/Data4/student_zhihan_data/data/GC10-DET/data.yaml')\n",
    "        if not os.path.exists(yaml_path):\n",
    "            print(yaml_path)\n",
    "        \n",
    "        # Read the YAML file\n",
    "        with open(yaml_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "\n",
    "        # Append the new key-value pair\n",
    "        if 'path' not in data:\n",
    "            data['path'] = '/Data4/student_zhihan_data/data/GC10-DET'\n",
    "        # Write the modified data structure back to the YAML file\n",
    "        with open(yaml_path, 'w') as file:\n",
    "            yaml.dump(data, file)\n",
    "        \n",
    "        model = YOLO(model_path)  # load a custom model\n",
    "        metrics = model.val(data='/Data4/student_zhihan_data/data/GC10-DET/data.yaml', device='0,1,2,3', split='val', verbose=False)  # no arguments needed, dataset and settings remembered \n",
    "        records[i] = metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([-10, -15, -20, -30, -50, -100, -150, 10, 0, 20, 30, 50, 60, 70, 90])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10 {'metrics/precision(B)': 0.6249449038647459, 'metrics/recall(B)': 0.5824428816724565, 'metrics/mAP50(B)': 0.6006457822208314, 'metrics/mAP50-95(B)': 0.2939694689322862, 'fitness': 0.32463710026114073}\n",
      "-15 {'metrics/precision(B)': 0.63540304991421, 'metrics/recall(B)': 0.557291941369644, 'metrics/mAP50(B)': 0.5786556628066502, 'metrics/mAP50-95(B)': 0.28753595728046305, 'fitness': 0.31664792783308177}\n",
      "-20 {'metrics/precision(B)': 0.6044578471210236, 'metrics/recall(B)': 0.5478730576783379, 'metrics/mAP50(B)': 0.5838985135774001, 'metrics/mAP50-95(B)': 0.290801130826919, 'fitness': 0.3201108691019671}\n",
      "-30 {'metrics/precision(B)': 0.5741561941486621, 'metrics/recall(B)': 0.5931305412688984, 'metrics/mAP50(B)': 0.5723564968996909, 'metrics/mAP50-95(B)': 0.28248264936649464, 'fitness': 0.3114700341198143}\n",
      "-50 {'metrics/precision(B)': 0.6644195087900344, 'metrics/recall(B)': 0.5700942856385729, 'metrics/mAP50(B)': 0.6035856265816145, 'metrics/mAP50-95(B)': 0.29331849781479236, 'fitness': 0.3243452106914746}\n",
      "-100 {'metrics/precision(B)': 0.5947803586621929, 'metrics/recall(B)': 0.5795931112742715, 'metrics/mAP50(B)': 0.5999287694061272, 'metrics/mAP50-95(B)': 0.2878062848652314, 'fitness': 0.319018533319321}\n",
      "-150 {'metrics/precision(B)': 0.4869671119186905, 'metrics/recall(B)': 0.3744646596479372, 'metrics/mAP50(B)': 0.38697335872609606, 'metrics/mAP50-95(B)': 0.16416541735700096, 'fitness': 0.1864462114939105}\n",
      "10 {'metrics/precision(B)': 0.534854981937438, 'metrics/recall(B)': 0.5503425273755495, 'metrics/mAP50(B)': 0.5546556558947012, 'metrics/mAP50-95(B)': 0.2699530844395611, 'fitness': 0.2984233415850751}\n",
      "0 {'metrics/precision(B)': 0.6299055138121173, 'metrics/recall(B)': 0.601450892462405, 'metrics/mAP50(B)': 0.6000783831490853, 'metrics/mAP50-95(B)': 0.30150018379405, 'fitness': 0.33135800372955354}\n",
      "20 {'metrics/precision(B)': 0.5680202401929388, 'metrics/recall(B)': 0.5490664885826269, 'metrics/mAP50(B)': 0.5496700606623386, 'metrics/mAP50-95(B)': 0.2650600213639469, 'fitness': 0.2935210252937861}\n",
      "30 {'metrics/precision(B)': 0.6231153704962735, 'metrics/recall(B)': 0.5565286366314192, 'metrics/mAP50(B)': 0.5838163798378416, 'metrics/mAP50-95(B)': 0.2886646484603545, 'fitness': 0.3181798215981032}\n",
      "50 {'metrics/precision(B)': 0.5676938201383777, 'metrics/recall(B)': 0.5701489954724703, 'metrics/mAP50(B)': 0.5587589465403755, 'metrics/mAP50-95(B)': 0.2755764159027562, 'fitness': 0.3038946689665182}\n",
      "60 {'metrics/precision(B)': 0.5778848321075294, 'metrics/recall(B)': 0.6354059758119094, 'metrics/mAP50(B)': 0.606969166457332, 'metrics/mAP50-95(B)': 0.30386058781996395, 'fitness': 0.3341714456837007}\n",
      "70 {'metrics/precision(B)': 0.6025696177934391, 'metrics/recall(B)': 0.49613325501116634, 'metrics/mAP50(B)': 0.5130623109949675, 'metrics/mAP50-95(B)': 0.24052717250438604, 'fitness': 0.2677806863534442}\n",
      "90 {'metrics/precision(B)': 0.6128944679892401, 'metrics/recall(B)': 0.5763767027267146, 'metrics/mAP50(B)': 0.5907102966612485, 'metrics/mAP50-95(B)': 0.2961961226874533, 'fitness': 0.3256475400848329}\n"
     ]
    }
   ],
   "source": [
    "for i in records:\n",
    "    print(i, records[i].results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/GC10-DET detect by yolov8n5/weights/best.pt')\n",
    "\n",
    "i = 0\n",
    "yaml_path = os.path.join('/Data4/student_zhihan_data/data/GC10-DET/data.yaml')\n",
    "if not os.path.exists(yaml_path):\n",
    "    print(yaml_path)\n",
    "\n",
    "# Read the YAML file\n",
    "with open(yaml_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# Append the new key-value pair\n",
    "data['path'] = '/Data4/student_zhihan_data/data/GC10-DET'\n",
    "\n",
    "# Write the modified data structure back to the YAML file\n",
    "with open('/Data4/student_zhihan_data/data/GC10-DET_brightness_-30/data.yaml', 'w') as file:\n",
    "    yaml.dump(data, file)\n",
    "    \n",
    "model = YOLO(model_path)  # load a custom model\n",
    "metrics = model.val(data='/Data4/student_zhihan_data/data/GC10-DET_brightness_%d/data.yaml' % i, device='0,1,2,3', split='val', verbose=False)  # no arguments needed, dataset and settings remembered \n",
    "records[i] = metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10 {'metrics/precision(B)': 0.674660866865132, 'metrics/recall(B)': 0.5701132068384447, 'metrics/mAP50(B)': 0.6120042593808653, 'metrics/mAP50-95(B)': 0.2997180743641319, 'fitness': 0.33094669286580525}\n",
      "-15 {'metrics/precision(B)': 0.6508055279996983, 'metrics/recall(B)': 0.5707156922718054, 'metrics/mAP50(B)': 0.5965976751415456, 'metrics/mAP50-95(B)': 0.2952428644227792, 'fitness': 0.3253783454946559}\n",
      "-20 {'metrics/precision(B)': 0.6115646182695766, 'metrics/recall(B)': 0.5578813141986456, 'metrics/mAP50(B)': 0.5977855761341153, 'metrics/mAP50-95(B)': 0.2960975543119524, 'fitness': 0.32626635649416874}\n",
      "-30 {'metrics/precision(B)': 0.5770876974552056, 'metrics/recall(B)': 0.623814996052056, 'metrics/mAP50(B)': 0.5998386724338385, 'metrics/mAP50-95(B)': 0.2960759379967164, 'fitness': 0.3264522114404286}\n",
      "-50 {'metrics/precision(B)': 0.6644195087900344, 'metrics/recall(B)': 0.5700942856385729, 'metrics/mAP50(B)': 0.6035856265816145, 'metrics/mAP50-95(B)': 0.29331849781479236, 'fitness': 0.3243452106914746}\n",
      "-100 {'metrics/precision(B)': 0.5947803586621929, 'metrics/recall(B)': 0.5795931112742715, 'metrics/mAP50(B)': 0.5999287694061272, 'metrics/mAP50-95(B)': 0.2878062848652314, 'fitness': 0.319018533319321}\n",
      "-150 {'metrics/precision(B)': 0.48166678138059255, 'metrics/recall(B)': 0.3969532036845596, 'metrics/mAP50(B)': 0.39173623656679235, 'metrics/mAP50-95(B)': 0.1671462835626861, 'fitness': 0.18960527886309672}\n",
      "10 {'metrics/precision(B)': 0.8692851940292151, 'metrics/recall(B)': 0.4396075629237476, 'metrics/mAP50(B)': 0.5249720746724105, 'metrics/mAP50-95(B)': 0.25624314505792173, 'fitness': 0.28311603801937063}\n",
      "20 {'metrics/precision(B)': 0.5315329102185066, 'metrics/recall(B)': 0.5454510889878013, 'metrics/mAP50(B)': 0.5382945370267745, 'metrics/mAP50-95(B)': 0.26289433987395205, 'fitness': 0.2904343595892343}\n",
      "30 {'metrics/precision(B)': 0.6415143231032876, 'metrics/recall(B)': 0.5784681266097652, 'metrics/mAP50(B)': 0.6039017483708441, 'metrics/mAP50-95(B)': 0.29635016822515164, 'fitness': 0.3271053262397209}\n",
      "50 {'metrics/precision(B)': 0.6360800655408384, 'metrics/recall(B)': 0.5330013591126862, 'metrics/mAP50(B)': 0.5738751512357536, 'metrics/mAP50-95(B)': 0.2714742146021708, 'fitness': 0.3017143082655291}\n",
      "60 {'metrics/precision(B)': 0.5773917165203, 'metrics/recall(B)': 0.6392890663388354, 'metrics/mAP50(B)': 0.6098038377780004, 'metrics/mAP50-95(B)': 0.3053066638804889, 'fitness': 0.3357563812702401}\n",
      "70 {'metrics/precision(B)': 0.602436784585489, 'metrics/recall(B)': 0.49210851145153905, 'metrics/mAP50(B)': 0.5086704378848104, 'metrics/mAP50-95(B)': 0.23870316460541158, 'fitness': 0.2656998919333515}\n",
      "90 {'metrics/precision(B)': 0.613115354242206, 'metrics/recall(B)': 0.5586430711421484, 'metrics/mAP50(B)': 0.5723559867457124, 'metrics/mAP50-95(B)': 0.28587436171736974, 'fitness': 0.314522524220204}\n"
     ]
    }
   ],
   "source": [
    "# records to csv\n",
    "import pandas\n",
    "columns = []\n",
    "columns.extend([i for i in records[10].results_dict.keys()])\n",
    "df = pandas.DataFrame(columns=columns)\n",
    "for i in records:\n",
    "    print(i, records[i].results_dict)\n",
    "    # add new row to df\n",
    "    df.loc[i] = records[i].results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train: ../train/images\\nval: ../valid/images\\ntest: ../test/images\\n\\nnc: 10\\nnames: ['crease', 'crescent_gap', 'inclusion', 'oil_spot', 'punching_hole', 'rolled_pit', 'silk_spot', 'waist_folding', 'water_spot', 'welding_line']\\n\\nroboflow:\\n  workspace: machinelearning-p49ei\\n  project: gc10-det-dataset\\n  version: 4\\n  license: Public Domain\\n  url: https://universe.roboflow.com/machinelearning-p49ei/gc10-det-dataset/dataset/4\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
