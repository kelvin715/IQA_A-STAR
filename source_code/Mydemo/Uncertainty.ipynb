{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def cal_entropy(prob):\n",
    "    \"\"\"\n",
    "    calculate entropy of each defect\n",
    "    \"\"\"\n",
    "    entropy = -1 * np.sum(prob * np.log2(prob))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def cal_entropy_one_image(img_path, model, times):\n",
    "    img_path_list = [img_path for i in range(times)]\n",
    "    results = model(img_path_list)\n",
    "    entropy = []\n",
    "    for re in results:\n",
    "        cls_all = re.cls_all\n",
    "        if len(cls_all) != 0:\n",
    "            cls_all = np.array(cls_all.cpu())\n",
    "            entropy_sum = 0\n",
    "            for i in range(len(cls_all)):\n",
    "                entropy_sum += cal_entropy(cls_all[i])\n",
    "            entropy.append(entropy_sum / len(cls_all)) \n",
    "        \n",
    "        #plot\n",
    "        im_array = re.plot()  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        # plot img\n",
    "        pyplot.imshow(im_array)\n",
    "        pyplot.show()     \n",
    "                \n",
    "    entropy_mean = np.mean(np.array(entropy))\n",
    "    \n",
    "    return entropy_mean, results\n",
    "\n",
    "\n",
    "# model = YOLO('yolov8-dropblock.yaml').load('/Data4/student_zhihan_data/data/GC10-DET/test/images/img_08_425391700_00198_jpg.rf.79baed4ea8e426615cf676e94acf6292.jpg')\n",
    "model = YOLO('/Data4/student_zhihan_data/source_code/yolo/ultralytics/runs/detect/GC10-DET_brightness_0 detect by yolov8n with dropout(p=0.1)/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_path = '/Data4/student_zhihan_data/data/GC10-DET_brightness_10/test/images/img_08_425391700_00198_jpg.rf.79baed4ea8e426615cf676e94acf6292.jpg'\n",
    "results = model([img_path for i in range(400)])\n",
    "\n",
    "# cal_entropy_one_image(img_path, model, 20)\n",
    "# img_path = '/Data4/student_zhihan_data/data/GC10-DET_brightness_-150/test/images/img_08_425391700_00198_jpg.rf.79baed4ea8e426615cf676e94acf6292.jpg'\n",
    "# cal_entropy_one_image(img_path, model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the output bounding boxes\n",
    "from sklearn.cluster import KMeans\n",
    "def cluster_bounding_boxes(bounding_boxes:np.ndarray, n_clusters=3, confs=None, threshold=0.5):\n",
    "    \"\"\"_summary_\n",
    "    Args:\n",
    "        bounding_boxes (_type_): shape (boxes_num, 4)\n",
    "        \n",
    "    Return:\n",
    "        total_variance should be weighted according to the numbers of corrosponding labels\n",
    "    \"\"\"\n",
    "    selected_data = bounding_boxes[confs > threshold]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, max_iter=1000).fit(selected_data)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    variances = []\n",
    "    cls_entropy = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_data = selected_data[labels == i]\n",
    "        variances.append(np.var(cluster_data, axis=0))\n",
    "        \n",
    "    \n",
    "    weighted_variance = np.array(variances) * np.bincount(labels, minlength=n_clusters).reshape(-1, 1) / np.sum(np.bincount(labels))\n",
    "    weighted_variance_sum = np.sum(np.mean(weighted_variance, axis=1))\n",
    "  \n",
    "    return selected_data, labels, variances, weighted_variance_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundingboxes = []\n",
    "boxes = []\n",
    "conf = []\n",
    "cls_conf = []\n",
    "for re in results:\n",
    "    conf.extend(re.boxes.conf.cpu())\n",
    "    tmp = re.boxes.xywhn\n",
    "    boxes.extend(re.boxes.cpu())\n",
    "    boundingboxes.extend(tmp.cpu())\n",
    "    cls_conf.extend(re.cls_all.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 3 #read ground truth\n",
    "boundingboxes = np.array(boundingboxes)\n",
    "conf = np.array(conf)\n",
    "cls_conf = np.array(cls_conf)\n",
    "selected_data, labels, variances, weighted_variance_sum = cluster_bounding_boxes(boundingboxes, n_clusters=cluster_num, confs=np.array(conf), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_path, weighted_variance_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectness_uncertainty = np.var(conf[conf > 0.5])\n",
    "objectness_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_cluster = []\n",
    "for i in range(cluster_num):\n",
    "    cluster = cls_conf[conf > 0.5][labels == i]\n",
    "    entropy = np.apply_along_axis(lambda x: -1 * np.sum(x * np.log2(x)), 1, cluster)\n",
    "    entropy_cluster.append(np.mean(entropy))\n",
    "\n",
    "weighted_entropy = np.mean(np.array(entropy_cluster) * np.bincount(labels, minlength=cluster_num).reshape(-1, 1) / np.sum(np.bincount(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "from ultralytics.utils.plotting import Annotator, Colors\n",
    "\n",
    "\n",
    "def visualize_cluster_results(results, selected_boxes, labels, specify):\n",
    "    # background = (results[0].orig_img[0].detach().permute(1, 2, 0).contiguous() * 255).to(torch.uint8).cpu().numpy()\n",
    "    background = results[0].orig_img\n",
    "    annotator = Annotator(\n",
    "        deepcopy(background),\n",
    "    )\n",
    "    \n",
    "    colors = Colors()\n",
    "    names = results[0].names\n",
    "    for id, re in enumerate(selected_boxes):\n",
    "        if labels[id] == specify:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        for d in reversed(re):\n",
    "            c, conf, id = int(d.cls), float(d.conf), None if d.id is None else int(d.id.item())\n",
    "            name = (\"\" if id is None else f\"id:{id} \") + names[c]\n",
    "            label = (f\"{name} {conf:.2f}\" if conf else name)\n",
    "            box = d.xyxy.squeeze()\n",
    "            annotator.box_label(box, label, color=colors(c, True), rotated=False)    \n",
    "    \n",
    "    im = Image.fromarray(annotator.result()[..., ::-1])  # RGB PIL image\n",
    "    # plot img\n",
    "    pyplot.imshow(im)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_boxes = []\n",
    "for id, box in enumerate(boxes):\n",
    "    if conf[id] > 0.5:\n",
    "        select_boxes.append(box)\n",
    "\n",
    "for i in range(cluster_num):\n",
    "    visualize_cluster_results(results, select_boxes, labels, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty(times, model):\n",
    "    dir = ['GC10-DET_BilateralBlur_'+str(i) for i in [60, 120, 180, 240, 300]]\n",
    "    dir.extend(['GC10-DET_MedianlBlur_'+str(i) for i in [15, 29, 43, 57, 71]])\n",
    "    \n",
    "    dir = [os.path.join('/Data4/student_zhihan_data/data',i) for i in dir]\n",
    "    for j in dir:\n",
    "        for i in range(len(os.listdir(os.path.join(j, 'test', 'images')))):\n",
    "        \n",
    "            img = os.listdir(os.path.join(j, \"test\", \"images\"))[i]\n",
    "            label = os.listdir(os.path.join(j, \"test\", \"labels\"))[i]\n",
    "            \n",
    "\n",
    "            img_path = os.path.join(j, \"test\", \"images\", img)\n",
    "            label_path = os.path.join(j, \"test\", \"labels\", label)\n",
    "        \n",
    "            results = model([img_path for i in range(times)], verbose=False)\n",
    "            \n",
    "            boundingboxes = []\n",
    "            boxes = []\n",
    "            conf = []\n",
    "            cls_conf = []\n",
    "            for re in results:\n",
    "                conf.extend(re.boxes.conf.cpu())\n",
    "                tmp = re.boxes.xywhn\n",
    "                boxes.extend(re.boxes.cpu())\n",
    "                boundingboxes.extend(tmp.cpu())\n",
    "                cls_conf.extend(re.cls_all.cpu())\n",
    "                \n",
    "            #read txt file\n",
    "            cluster_num = len(np.loadtxt(label_path))\n",
    "            boundingboxes = np.array(boundingboxes)\n",
    "            conf = np.array(conf)\n",
    "            cls_conf = np.array(cls_conf)\n",
    "            selected_data, labels, variances, weighted_variance_sum = cluster_bounding_boxes(boundingboxes, n_clusters=cluster_num, confs=np.array(conf), threshold=0.5)\n",
    "            \n",
    "            objectness_uncertainty = np.var(conf[conf > 0.5])\n",
    "            \n",
    "            entropy_cluster = []\n",
    "            for n in range(cluster_num):\n",
    "                cluster = cls_conf[conf > 0.5][labels == n]\n",
    "                entropy = np.apply_along_axis(lambda x: -1 * np.sum(x * np.log2(x)), 1, cluster)\n",
    "                entropy_cluster.append(np.mean(entropy))\n",
    "\n",
    "            weighted_entropy = np.mean(np.array(entropy_cluster) * np.bincount(labels, minlength=cluster_num).reshape(-1, 1) / np.sum(np.bincount(labels)))\n",
    "            \n",
    "            print(f'{j}:objectness_uncertainty: {objectness_uncertainty}, weighted_variance_sum: {weighted_variance_sum}, weighted_entropy: {weighted_entropy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty(400, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
